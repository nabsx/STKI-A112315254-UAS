{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis Sentimen Tweet Cryptocurrency: Mengukur Sentimen Pasar melalui Media Sosial\n",
    "\n",
    "## Identitas\n",
    "## Nama: Nabhaan Auryshafa Adhigana\n",
    "## NIM: A11.2023.15254\n",
    "## Kelas: A11.4517\n",
    "\n",
    "## Import Library yang Dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# untuk text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# untuk modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Ringkasan dan Permasalahan Project\n",
    "\n",
    "### 1.1 Latar Belakang\n",
    "\"\"\"\n",
    "[Cryptocurrency merupakan aset digital yang sangat dipengaruhi oleh sentimen pasar Media sosial, khususnya Twitter, menjadi platform utama diskusi crypto]\n",
    "\"\"\"\n",
    "\n",
    "### 1.2 Rumusan Masalah\n",
    "\"\"\"\n",
    "[Perlu sistem untuk menganalisis sentimen tweet untuk memahami tren pasar]\n",
    "\"\"\"\n",
    "\n",
    "### 1.3 Tujuan\n",
    "\"\"\"\n",
    "[Mengembangkan model ML untuk mengklasifikasikan sentimen tweet crypto (positif/negatif/netral)]\n",
    "\"\"\"\n",
    "\n",
    "### Alur Penyelesaian (Bagan)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(\"alur.jpg\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Dataset dan Preprocessing\n",
    "\n",
    "### 2.1 Load Dataset\n",
    "# Load dataset\n",
    "df = pd.read_csv('crypto_data.csv')\n",
    "\n",
    "# Tampilkan beberapa baris pertama\n",
    "print(\"Sample data:\")\n",
    "df.head()\n",
    "\n",
    "### 2.2 Exploratory Data Analysis (EDA)\n",
    "\n",
    "# Info dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Statistik deskriptif\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "df.describe()\n",
    "\n",
    "# Visualisasi distribusi tweet berdasarkan waktu\n",
    "plt.figure(figsize=(12, 6))\n",
    "# [Kode visualisasi akan ditambahkan]\n",
    "plt.title('Distribusi Tweet Berdasarkan Waktu')\n",
    "plt.show()\n",
    "\n",
    "### 2.3 Text Preprocessing\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Function untuk membersihkan dan preprocessing text\n",
    "    \"\"\"\n",
    "    # Convert ke lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove mentions dan hashtags\n",
    "    text = re.sub(r'@\\w+|\\#\\w+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "### 3.1 TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "### 3.2 Split Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Model Development\n",
    "\n",
    "### 4.1 Naive Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "print(\"Naive Bayes Performance:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "### 4.2 SVM Model\n",
    "svm_model = LinearSVC(random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluasi\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "print(\"\\nSVM Performance:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Evaluasi Model\n",
    "\n",
    "### 5.1 Confusion Matrix\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Confusion Matrix untuk Naive Bayes\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_nb), annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix - Naive Bayes')\n",
    "\n",
    "# Confusion Matrix untuk SVM\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d')\n",
    "plt.title('Confusion Matrix - SVM')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "### 5.2 Error Analysis\n",
    "\"\"\"\n",
    "[Keterbatasan Model:\n",
    "\n",
    "Model belum optimal dalam memahami singkatan dan jargon crypto\n",
    "Kesulitan dalam menginterpretasi emoji dan simbol yang sering digunakan dalam tweet\n",
    "Keterbatasan dalam memahami konteks thread atau percakapan yang berkelanjutan]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Diskusi dan Kesimpulan\n",
    "\n",
    "### 6.1 Interpretasi Hasil\n",
    "\"\"\"\n",
    "[Interpretasi hasil dari model yang telah dibuat]\n",
    "\"\"\"\n",
    "\n",
    "### 6.2 Kesimpulan\n",
    "\"\"\"\n",
    "[Kesimpulan dari keseluruhan project]\n",
    "\"\"\"\n",
    "\n",
    "### 6.3 Saran Pengembangan\n",
    "\"\"\"\n",
    "[Saran untuk pengembangan lebih lanjut]\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
